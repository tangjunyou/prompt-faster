---
stepsCompleted: [1, 2, 3, 4]
inputDocuments: []
session_topic: 'Dify Prompt 自动化优化平台'
session_goals: '设计一个能够自动优化 Dify 工作流 prompt 的 Web 应用'
selected_approach: 'AI-Recommended Techniques'
techniques_used: ['需求挖掘', '风险分析', '架构设计', '状态管理设计', '用户体验设计', '成熟方案对标']
ideas_generated: ['分层优化架构', '三层状态管理', 'Checkpoint机制', '动态工作记忆', '工作区概念', '老师模型分阶段Prompt架构', '双模式人机协作']
context_file: '.bmad/bmm/data/project-context-template.md'
---

# 头脑风暴会话报告

**引导者:** Mary (Business Analyst)
**参与者:** 耶稣
**日期:** 2025-12-12
**项目:** Dify Prompt 自动化优化平台

---

## 1. 项目概述

### 1.1 核心目标

开发一个 Web 应用，能够**自动化优化 Dify 工作流中的 prompt**，通过 AI 辅助迭代，最终输出一个能够通过所有测试集的高质量 prompt。

### 1.2 项目背景

- **痛点**: Dify 工作流的 prompt 优化需要大量人工试错
- **解决方案**: 利用 AI（老师模型）自动分析测试集、总结规律、迭代优化 prompt
- **目标用户**: 使用 Dify 构建工作流的开发者/产品经理

---

## 2. 核心功能需求

### 2.1 API 配置模块

| 功能 | 描述 |
|------|------|
| Dify API 配置 | 输入 Dify 工作流 API 地址和 API Key |
| 老师模型配置 | 配置硅基流动（或其他）AI 模型参数 |
| 连接测试 | 验证两个 API 是否可正常调用 |
| 凭证持久化 | 本地保存配置，下次无需重新填写 |

### 2.2 变量解析模块

| 功能 | 描述 |
|------|------|
| 自动解析 | 调用 Dify API 获取工作流的所有输入变量 |
| 变量分类 | 用户指定哪个变量是 `system prompt`（待优化） |
| 其他变量 | 其余变量作为 `user prompt` 传入 Dify |

### 2.3 测试集管理模块

| 功能 | 描述 |
|------|------|
| 创建测试集 | 每组包含：输入变量值 + 标准答案 |
| 输入方式 | 手动填写 或 上传 txt 文档（保持格式不变） |
| 预期规模 | 用户自定义，1组也可以，无上限 |
| 模板功能 | 常用配置可保存为模板复用 |

### 2.4 核心目标输入

- 用户以**自然语言**描述优化目标
- 例如："生成的回答需要简洁专业，不超过200字"

### 2.5 自动优化引擎

#### 2.5.1 分层优化架构

```
┌─────────────────────────────────────────────────────────────┐
│  Layer 1: 规律抽取层                                          │
│  ├─ 输入：测试集 + 标准答案 + 核心目标                          │
│  ├─ 输出：2-3个候选规律假设（用户可配置数量）                    │
│  └─ 关键：多角度假设，降低单点失败风险                           │
├─────────────────────────────────────────────────────────────┤
│  Layer 2: Prompt 生成层                                       │
│  ├─ 输入：规律假设 + 格式选择（Markdown/JSON/XML）              │
│  ├─ 输出：候选 prompt（可生成多个变体）                         │
│  └─ 关键：AI 智能选择最优格式                                   │
├─────────────────────────────────────────────────────────────┤
│  Layer 3: 评估反馈层                                          │
│  ├─ 执行：调用 Dify 跑所有测试集                                │
│  ├─ 检测：相似度（ROUGE-L/BLEU/Jaccard/LLM评分，用户可选）      │
│  ├─ 判断：老师模型验证是否符合核心目标                           │
│  └─ 输出：通过/失败 + 详细诊断报告                              │
├─────────────────────────────────────────────────────────────┤
│  Layer 4: 反思迭代层                                          │
│  ├─ 输入：失败诊断 + 历史记录 + 失败档案                        │
│  ├─ 检查：新方向是否和历史失败重复？                             │
│  ├─ 机制：连续3次失败触发多样性注入（用户可配置阈值）             │
│  └─ 输出：规律修正 / 新 prompt 方向                            │
└─────────────────────────────────────────────────────────────┘
```

#### 2.5.2 防过拟合策略

- **禁止显性提示**: prompt 中不能包含针对特定测试案例的硬编码内容
- **规律性提示**: 只允许抽象通用的规则描述

#### 2.5.3 迭代控制

| 参数 | 说明 | 默认值 |
|------|------|--------|
| 迭代轮数 | 用户自选，跑完所有测试集算1轮 | - |
| 候选数量 | 规律假设/prompt变体的数量 | 2-3个 |
| 失败阈值 | 连续失败多少次触发多样性注入 | 3次 |

### 2.6 可视化与人工介入

#### 2.6.1 可视化要求

- **节点图形式**: 类似 Dify 工作流的节点流动展示
- **流式输出**: 实时展示老师模型的思考过程
- **数据清晰**: 每个节点展示当前状态数据
- **动画流畅**: 平滑的状态转换动画
- **流动可视化**: 数据在各环节像水流一样流动，不是静态展示
- **透明思考**: 老师模型的"思考过程"可见，不是黑盒
- **实时监控**: 用户可以实时看到整个迭代过程

#### 2.6.2 人工介入

- **全流程可介入**: 任何迭代阶段都可暂停
- **可修改内容**: 规律假设、prompt、参数等一切中间状态
- **断点续传**: 修改后可继续迭代
- **双模式介入**: 
  - **直接编辑** — 快速修正明显错误
  - **对话引导** — 告诉老师模型你的想法，让它重新生成
- **智能权限**: 只开放"会影响后续迭代"的内容让用户修改，避免无效操作
- **动态轮数**: 用户可随时增加迭代轮数，不设死限
- **无缝续接**: 修改后立刻继续，不破坏流程

### 2.7 历史与导出

| 功能 | 描述 |
|------|------|
| 版本对比 | 对比不同版本 prompt 在任务上的差距 |
| 导出功能 | 复制或导出最终 prompt |
| 格式支持 | Markdown / JSON / XML |

---

## 3. 状态管理架构

### 3.1 三层状态架构

```
┌─────────────────────────────────────────────────────────────┐
│  Layer 1: 持久存储层（SQLite）                                │
│  ├─ 测试集完整数据                                            │
│  ├─ 所有历史 prompt 版本                                      │
│  ├─ 完整迭代日志（每一步的输入/输出）                           │
│  ├─ 失败档案（prompt + 输出 + 原因分析）                       │
│  └─ 用户配置、API 凭证                                        │
├─────────────────────────────────────────────────────────────┤
│  Layer 2: 会话状态层（Checkpoint）                            │
│  ├─ 当前优化任务上下文                                        │
│  ├─ 当前迭代轮次 & 步骤                                       │
│  ├─ 当前最佳 prompt & 得分                                    │
│  ├─ 累积的规律假设（可多个）                                   │
│  └─ 支持回滚到任意历史节点                                     │
├─────────────────────────────────────────────────────────────┤
│  Layer 3: 工作记忆层（动态构建）                               │
│  └─ 根据任务类型，智能选择相关信息传给老师模型                   │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 工作记忆动态构建

| 任务类型 | 输入内容 | 输出 |
|----------|----------|------|
| 初始规律总结 | 核心目标 + 所有测试集概要 + 标准答案 | 2-3个规律假设 |
| Prompt 生成 | 核心目标 + 选定规律 + 格式要求 | 候选 prompt |
| 失败反思 | 核心目标 + 当前规律 + 当前prompt + 仅失败测试 + 最近失败摘要 | 原因分析 + 修正建议 |
| 规律更新 | 当前规律 + 累积失败经验摘要 + 成功案例共性 | 更新后的规律 |

### 3.3 摘要压缩策略

- **方案**: 老师模型自动生成摘要（更智能）
- **目的**: 控制上下文大小，同时保留关键信息

### 3.4 Checkpoint 机制

```typescript
interface Checkpoint {
  id: string;                    // 唯一标识
  timestamp: Date;               // 时间戳
  iteration: number;             // 第几轮迭代
  step: "rules" | "prompt" | "test" | "reflect" | "update";
  
  // 状态数据
  currentRules: Rule[];          // 当前规律假设
  currentPrompt: string;         // 当前 prompt
  testResults: TestResult[];     // 测试结果
  failureArchive: Failure[];     // 失败档案
  
  // 元数据
  parentId: string | null;       // 父 checkpoint
  metadata: Record<string, any>;
}
```

- **粒度**: 每步都存（支持任意回滚）
- **用途**: 人工介入、历史回溯、状态恢复

---

## 4. 保障机制

### 4.1 失败档案

记录每次失败：
- 失败的 prompt 内容
- 失败的测试集
- 输出 vs 标准答案的差异
- 诊断出的原因

**目的**: 新 prompt 生成前检查是否重蹈覆辙

### 4.2 多样性注入

- **触发条件**: 连续 N 次失败（默认3次，用户可配置）
- **执行动作**: 强制换策略（换格式、换表达风格、尝试不同规律假设）

### 4.3 回退机制

- 如果新版本比上一版更差 → 回退 + 尝试其他方向
- 保留"最佳历史版本"作为兜底

### 4.4 成功标准

| 模式 | 判断逻辑 |
|------|----------|
| **系统自动** | 所有测试集通过（相似度 ≥ 用户设定阈值 + 老师模型确认符合核心要求） |
| **用户主导** | 用户随时可中止 + 手动选取满意的 prompt |
| **数据保障** | 全程持久化，可回看、可续做 |

### 4.5 失败场景处理

- **老师诊断 + 用户决策**: 当始终有测试集过不了时，老师模型给出判断和建议，由用户决定怎么处理（改测试集？换策略？接受现状？）
- 系统不应自动"帮用户改"，最终决策权在用户手上

### 4.6 结构化反思模板

```markdown
## 反思框架（强制老师模型按此执行）
1. 本次失败的具体表现是什么？
2. 和标准答案对比，差在哪里？
3. 当前 prompt 的哪个部分导致了这个差异？
4. 应该如何修改？给出具体建议
5. 这个修改是否会影响其他测试集？
```

---

## 5. 非功能需求

### 5.1 用户系统

| 项目 | 规格 |
|------|------|
| 登录方式 | 本地注册/登录（类似 Dify Docker 部署） |
| 多用户 | 单人使用，不需要多人协作 |
| 凭证安全 | 仅本地存储，不联网 |

### 5.2 多项目管理（工作区概念）

- **工作区**: 每个优化任务独立的工作区，切换查看不同的并行优化任务
- **老师模型配置**: 可配多个老师模型，持久化保存，随时切换使用
- **隔离性**: 工作区之间数据完全独立（测试集、配置、历史记录）
- 支持创建多个优化项目

### 5.3 异常处理

| 场景 | 处理方式 |
|------|----------|
| 网络中断 | 自动重试 → 失败反馈 → 用户修复后断点续传 |
| 响应超时 | 继续等待（流式输出让用户感知过程） |
| API 错误 | 准确报错，不丢失迭代进度 |

### 5.4 国际化

- 中文为主，英文为辅
- 界面支持中英文切换

---

## 6. 技术选型

| 层面 | 技术选择 |
|------|----------|
| 后端 | Rust |
| 前端 | TypeScript |
| 数据库 | SQLite（本地轻量） |
| 部署 | Docker（开发完成后容器化） |
| 平台支持 | Windows + macOS |
| 浏览器 | Chrome、Edge、Safari |

---

## 7. 成熟方案参考

### 7.1 方案概览

| 方案 | 核心思路 | 借鉴点 |
|------|----------|--------|
| **OPRO** (DeepMind) | 用 LLM 优化 prompt | 迭代优化机制 |
| **Reflexion** | Agent 自我反思 | 反思阶段设计 |
| **LangGraph** | 状态图管理 + Checkpoint | 状态管理架构 |
| **MemGPT** | 分层记忆管理 | 工作记忆动态构建 |
| **DSPy** | 声明式 prompt 优化 | 测试集管理思路 |
| **PromptWizard** (Microsoft) | Mutation + Refinement | 多变体生成 |

### 7.2 OPRO 深度分析（最接近本项目的核心机制）

**论文**: *Large Language Models as Optimizers* (2023, DeepMind)

**核心架构**:
```
┌─────────────────────────────────────────────────────────────┐
│  Meta-Prompt（元提示）                                        │
│  ├─ 任务描述                                                  │
│  ├─ 历史方案 + 分数（按分数排序）                               │
│  ├─ 少量示例（可选）                                          │
│  └─ 生成指令："生成一个比历史更好的新方案"                       │
├─────────────────────────────────────────────────────────────┤
│  Optimizer LLM → 生成候选方案                                  │
├─────────────────────────────────────────────────────────────┤
│  Scorer LLM → 评估候选方案，输出分数                            │
├─────────────────────────────────────────────────────────────┤
│  更新历史池 → 保留最佳方案 → 下一轮迭代                          │
└─────────────────────────────────────────────────────────────┘
```

**对应关系**:
| OPRO 概念 | 本项目对应 |
|-----------|-------------|
| Meta-prompt | 老师模型的输入（规律+历史+目标） |
| Optimizer LLM | 老师模型（生成规律/prompt） |
| Scorer LLM | 老师模型+相似度评估 |
| 历史方案池 | 失败档案 + 历史prompt版本 |

**核心借鉴**:
- 把历史分数放入上下文，让老师模型看到"什么分数高、什么分数低"
- 进化式搜索，基于历史最佳继续优化

### 7.3 Reflexion 深度分析（最接近本项目的反思机制）

**论文**: *Reflexion: Language Agents with Verbal Reinforcement Learning* (2023)

**核心架构**:
```
┌─────────────────────────────────────────────────────────────┐
│  Actor（执行者）→ 生成方案                                     │
├─────────────────────────────────────────────────────────────┤
│  Evaluator（评估者）→ 执行测试，返回通过/失败 + 反馈             │
├─────────────────────────────────────────────────────────────┤
│  Self-Reflection（自我反思）→ 分析失败原因，生成改进建议          │
├─────────────────────────────────────────────────────────────┤
│  Memory（记忆）→ 存储历史反思，下次生成时作为上下文               │
└─────────────────────────────────────────────────────────────┘
```

**反思策略枚举**:
```python
class ReflexionStrategy:
    LAST_ATTEMPT              # 只看上一次尝试
    REFLEXION                 # 只看反思总结
    LAST_ATTEMPT_AND_REFLEXION  # 两者都看
```

**核心借鉴**:
- 结构化反思模板，强制回答"哪里错了？为什么？怎么改？"
- 记忆策略可选，用户可以选择"只看上次"还是"看完整历史"
- 语言强化学习，用自然语言描述失败

### 7.4 DSPy SIMBA 深度分析（困难样本处理）

**核心机制**:
```
┌─────────────────────────────────────────────────────────────┐
│  Step 1: 小批量采样 → 随机抽取部分测试集运行多次                 │
├─────────────────────────────────────────────────────────────┤
│  Step 2: 识别困难样本 → 找出"高变异性"的测试用例                 │
├─────────────────────────────────────────────────────────────┤
│  Step 3: 自省分析 → LLM分析困难样本，生成"自反思改进规则"         │
├─────────────────────────────────────────────────────────────┤
│  Step 4: 规则应用 → 把成功案例加入few-shot，或把规则加入指令      │
└─────────────────────────────────────────────────────────────┘
```

**核心借鉴**:
- 专门处理困难样本，重点分析"顽固"的测试集
- 生成自反思规则，不只是改prompt，而是生成可复用的规则

### 7.5 PromptWizard 深度分析（多变体生成）

**核心机制**:
```yaml
mutation_rounds: 5          # 变异轮数
mutate_refine_iterations: 3 # 变异+精炼迭代
style_variation: 4          # 风格变体数量
generate_expert_identity: true  # 生成专家身份
generate_intent_keywords: true  # 生成意图关键词
```

**核心借鉴**:
- 先定义专家身份，让老师模型先"定义自己是谁"
- 变异+精炼分离，前期多变体探索，后期收敛精炼

### 7.6 本项目定位：多框架融合

```
┌─────────────────────────────────────────────────────────────┐
│  Dify Prompt 自动优化平台 = 多框架融合                         │
├─────────────────────────────────────────────────────────────┤
│  ◆ 迭代优化机制 ← OPRO (Meta-prompt + 历史分数)               │
│  ◆ 反思+记忆机制 ← Reflexion (Self-Reflection + Memory)       │
│  ◆ 困难样本处理 ← DSPy SIMBA (识别+专项分析)                   │
│  ◆ 多变体生成 ← PromptWizard (Mutation + Expert Identity)     │
│  ◆ 状态管理 ← LangGraph (Checkpoint + StateGraph)             │
├─────────────────────────────────────────────────────────────┤
│  ✨ 本项目独特价值                                            │
│  ├─ 针对 Dify 工作流的特定场景                                 │
│  ├─ 人工介入机制（不是纯自动化）                               │
│  ├─ 实时可视化流程                                            │
│  └─ 双模式成功标准（系统判断 + 用户判断）                       │
└─────────────────────────────────────────────────────────────┘
```

### 7.7 具体可落地的借鉴清单

| 来源 | 借鉴点 | 如何应用 |
|------|--------|---------|
| **OPRO** | Meta-prompt 包含历史分数 | 老师模型输入中加入"历史prompt+分数排名" |
| **OPRO** | 双LLM架构 | 可考虑用不同模型做"生成"和"评估" |
| **Reflexion** | 反思策略可选 | 用户可选"只看上次失败"或"看完整历史" |
| **Reflexion** | 结构化反思 | 强制老师回答固定问题模板 |
| **SIMBA** | 识别困难样本 | 专门标记"连续N次失败"的测试用例 |
| **SIMBA** | 生成自反思规则 | 不只改prompt，还输出"以后遵守的规则" |
| **PromptWizard** | Expert Identity | 让老师先定义任务的"专家人设" |
| **PromptWizard** | 变异+精炼分离 | 前期多变体探索，后期收敛精炼 |

---

## 8. 老师模型分阶段 Prompt 架构

本项目的老师模型需要在不同阶段加载不同的 Prompt，每层有**专属角色 + 强制推理结构**。

### 8.1 Layer 1: 规律抽取层 Prompt

| 维度 | 设计 |
|------|------|
| **角色** | Pattern Extractor（模式提取专家） |
| **输入** | 核心目标 + 测试集概要 + 标准答案 |
| **强制结构** | 1️⃣ 逐条分析测试集共性 → 2️⃣ 归纳抽象规律 → 3️⃣ 输出2-3个候选假设 |
| **借鉴** | DSPy 的 `ChainOfThought` —— 强制先推理再输出 |

```markdown
你是一个模式提取专家。你的任务是从测试集中发现隐含规律。

## 输入
- 核心目标：{goal}
- 测试集：{test_cases}

## 要求
1. 先逐条分析：每个标准答案有什么共同特征？
2. 再归纳抽象：这些特征背后的通用规律是什么？
3. 输出2-3个候选规律假设（从不同角度）

## 输出格式
[推理过程]
...你的分析...

[规律假设]
1. ...
2. ...
```

### 8.2 Layer 2: Prompt 生成层 Prompt

| 维度 | 设计 |
|------|------|
| **角色** | Prompt Engineer（提示词工程师） |
| **输入** | 选定的规律假设 + 格式偏好（Markdown/JSON/XML） |
| **强制结构** | 1️⃣ 理解规律 → 2️⃣ 设计 prompt 结构 → 3️⃣ 生成多个变体 |
| **借鉴** | PromptWizard 的 `mutation + style_variation` |

```markdown
你是一个 Prompt 工程师。你的任务是将规律转化为高质量的 system prompt。

## 输入
- 核心目标：{goal}
- 规律假设：{rule}
- 格式偏好：{format}

## 要求
1. 先理解规律的核心要点
2. 设计 prompt 的逻辑结构
3. 生成2个风格变体（一个简洁、一个详细）

## 禁止
- 不得包含针对特定测试案例的硬编码内容
- 只允许抽象通用的规则描述
```

### 8.3 Layer 3: 评估反馈层 Prompt

| 维度 | 设计 |
|------|------|
| **角色** | Quality Assessor（质量评估师） |
| **输入** | Dify 输出 + 标准答案 + 核心目标 |
| **强制结构** | 1️⃣ 逐条对比 → 2️⃣ 量化差距 → 3️⃣ 输出诊断报告 |
| **借鉴** | DSPy 的 metric evaluation —— 结构化评分 |

```markdown
你是一个质量评估师。你的任务是判断输出是否符合要求。

## 输入
- 核心目标：{goal}
- 测试用例：{test_case}
- 标准答案：{expected}
- 实际输出：{actual}

## 评估步骤
1. 语义一致性：输出的核心意思和标准答案是否一致？
2. 格式符合度：是否满足核心目标中的格式要求？
3. 信息完整性：有无遗漏或多余的关键信息？

## 输出（JSON格式）
{
  "pass": true/false,
  "similarity_score": 0.0-1.0,
  "diagnosis": "具体问题描述",
  "suggestion": "改进方向"
}
```

### 8.4 Layer 4: 反思迭代层 Prompt

| 维度 | 设计 |
|------|------|
| **角色** | Reflection Agent（反思代理） |
| **输入** | 失败诊断 + 历史失败档案摘要 + 当前规律/prompt |
| **强制结构** | 1️⃣ 分析根因 → 2️⃣ 检查历史避免重蹈覆辙 → 3️⃣ 提出修正方案 |
| **借鉴** | Reflexion 论文 —— 自我反思机制 |

```markdown
你是一个反思代理。你的任务是分析失败原因并提出修正方案。

## 输入
- 当前规律：{current_rule}
- 当前 prompt：{current_prompt}
- 失败测试：{failed_tests}
- 历史失败摘要：{failure_archive_summary}

## 反思步骤
1. 失败根因：这次失败的根本原因是什么？
2. 历史检查：这个问题在历史失败中出现过吗？之前的修改为什么没解决？
3. 修正方案：
   - 如果是规律问题 → 输出规律修正建议
   - 如果是表达问题 → 输出 prompt 修改建议
   - 如果连续失败3次 → 建议换策略方向

## 禁止
- 不得重复历史失败的修改方向
```

### 8.5 关键设计原则

| 原则 | 来源 | 应用 |
|------|------|------|
| **强制推理结构** | DSPy ChainOfThought | 每层 prompt 都有 `[推理过程]` 区块，防止模型跳步 |
| **多变体生成** | PromptWizard mutation | 规律抽取和 Prompt 生成都输出多个候选 |
| **结构化输出** | 通用最佳实践 | 评估层输出 JSON，方便程序解析 |
| **历史感知** | Reflexion | 反思层强制检查历史失败档案 |

---

## 9. 任务模式分类

### 9.1 双模式设计

| 任务模式 | 测试集模板 | 评估标准 | 成功条件 |
|----------|------------|----------|----------|
| **信息提取类** | Dify变量 + 标准答案 | 相似度算法 + 老师模型判断 | 所有测试集通过 |
| **创意类** | Dify变量（无标准答案） | 仅老师模型判断是否满足核心需求 | 所有测试集通过 |

### 9.2 约束条件模板（创意类任务）

用户可选填的结构化约束，插入老师模型 Prompt 作为判断依据：

| 约束类型 | 示例 | 若未填写 |
|----------|------|----------|
| 长度限制 | "不超过200字" | 插入"无" |
| 必含关键词 | "必须包含品牌名" | 插入"无" |
| 禁止内容 | "不能出现竞品名称" | 插入"无" |
| 格式要求 | "需要分3个段落" | 插入"无" |

### 9.3 输出多样性检测（创意类任务）

- **目的**: 防止 Prompt 过拟合到某种固定模式
- **机制**: 检测多个测试集输出的多样性分数
- **用途**: 可选开启，用于评估 Prompt 的创意能力

---

## 10. 元优化架构

### 10.1 核心问题

> **老师模型的 Prompt 本身，谁来优化？**

老师模型 Prompt 的质量**直接决定了整个系统的上限**。

### 10.2 多层级优化策略

| 层级 | 内容 | 可优化性 |
|------|------|----------|
| **L0: 基础 Prompt** | 开发者手写的初始老师模型 Prompt | 起点必须极其优秀 |
| **L1: 用户可调** | 高级用户可修改老师模型 Prompt | ✅ |
| **L2: 元优化** | 用本系统优化老师模型 Prompt（递归应用） | ✅ |
| **L3: 数据驱动** | 基于成功率统计自动进化 | ✅ |

### 10.3 关键约束

- **全版本持久化**: 所有老师模型 Prompt 版本必须保存，可回溯
- **成功率统计**: 每个版本在各类任务中的成功率、优化指标
- **数据支撑**: 为后续迭代（自动/手动/用户）提供依据

### 10.4 统计指标

| 指标 | 说明 |
|------|------|
| 任务成功率 | 该版本 Prompt 在多少任务中成功优化 |
| 平均迭代轮数 | 平均需要多少轮迭代才能成功 |
| 任务类型分布 | 在不同任务类型（信息提取/创意类）中的表现 |
| 用户满意度 | 用户手动终止时选择的版本分布 |

---

## 11. 风险识别

| 风险 | 描述 | 缓解措施 |
|------|------|----------|
| 少样本问题 | 10组测试集能否总结可靠规律？ | 渐进式规律构建 + 多候选假设 |
| 迭代死循环 | 改A坏B，改B坏A | 失败档案 + 去重检测 + 多样性注入 |
| 老师模型能力 | 模型能否做好元认知反思？ | 结构化反思模板 + 可替换模型 |
| 泛化性 | 规律是否真的通用？ | 禁止显性提示 + 规律性约束 |

---

## 12. 待决策事项

暂无重大待决策事项，核心需求已明确。

---

## 13. 下一步行动

1. **产品简报 (Product Brief)** - 可选，进一步精炼产品定位
2. **PRD (产品需求文档)** - 将头脑风暴成果转化为正式需求文档
3. **技术架构设计** - 基于需求设计详细系统架构
4. **创建 Epics 和 Stories** - 拆分为可执行的开发任务

---

## 附录：会话记录摘要

### 第一轮会话（2025-12-12 上午）

本次头脑风暴共探讨了以下主题：
- 项目核心流程设计
- API 配置与变量解析机制
- 测试集管理与评估标准
- 迭代优化算法（分层架构）
- AI 老师模型状态管理
- 防过拟合策略
- 人工介入机制
- 可视化设计
- 技术栈选型
- 异常处理与容错

**会话时长**: 约 1 小时
**产出质量**: 高（需求完整度较高，可直接进入 PRD 阶段）

### 第二轮会话（2025-12-12 下午）

继续深入探讨以下主题：

**用户体验设计**:
- 流动可视化：数据在各环节像水流一样流动
- 透明思考：老师模型的思考过程可见
- 双模式介入：直接编辑 + 对话引导
- 智能权限：只开放会影响后续的内容给用户修改
- 动态轮数：用户可随时增加迭代轮数

**成功标准细化**:
- 系统自动判断：所有测试集通过
- 用户主导判断：随时中止 + 手动选取
- 失败场景：老师诊断 + 用户决策

**工作区概念**:
- 每个优化任务独立工作区
- 老师模型配置可多个、可切换

**成熟方案深度对标**:
- OPRO (DeepMind)：Meta-prompt + 历史分数机制
- Reflexion：自我反思 + 记忆策略
- DSPy SIMBA：困难样本识别 + 自反思规则
- PromptWizard：Expert Identity + 变异精炼

**老师模型分阶段 Prompt 架构**:
- Layer 1：规律抽取层（Pattern Extractor）
- Layer 2：Prompt 生成层（Prompt Engineer）
- Layer 3：评估反馈层（Quality Assessor）
- Layer 4：反思迭代层（Reflection Agent）

**会话时长**: 约 30 分钟
**产出质量**: 高（补充了用户体验细节和成熟方案深度对标）

### 第三轮会话（2025-12-12 下午续）

继续深入探讨以下主题：

**任务模式分类**:
- 信息提取类：相似度算法 + 老师模型判断
- 创意类：仅老师模型判断是否满足核心需求
- 约束条件模板：结构化约束作为选填补充
- 输出多样性检测：防止 Prompt 过拟合

**流式输出技术确认**:
- Dify Workflow API 原生支持 `response_mode: "streaming"`
- SSE 流式返回，Rust 后端可完美处理
- 老师模型支持流式就流式，Dify 支持就流式

**元优化架构**:
- 老师模型 Prompt 的多层级优化策略
- L0 基础 Prompt（开发者手写）→ L1 用户可调 → L2 元优化（递归应用）→ L3 数据驱动进化
- 全版本持久化 + 成功率统计 + 数据支撑迭代

**会话时长**: 约 30 分钟
**产出质量**: 高（完成了任务模式设计和元优化架构设计）
